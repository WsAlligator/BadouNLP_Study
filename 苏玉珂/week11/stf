import json
import torch
from transformers import (
    BertTokenizer,
    BertForMaskedLM,
    Trainer,
    TrainingArguments,
    DataCollatorForLanguageModeling
)
from datasets import Dataset

class NewsSFTTrainer:
    def __init__(self, model_name='bert-base-chinese'):
        # 初始化tokenizer和模型
        self.tokenizer = BertTokenizer.from_pretrained(model_name)
        self.model = BertForMaskedLM.from_pretrained(model_name)
        self.data_collator = DataCollatorForLanguageModeling(
            tokenizer=self.tokenizer,
            mlm=False  # 不使用masked language modeling
        )
        
        # 添加特殊token
        special_tokens = {'sep_token': '<sep>', 'eos_token': '<eos>'}
        self.tokenizer.add_special_tokens({'additional_special_tokens': list(special_tokens.values())})
        self.model.resize_token_embeddings(len(self.tokenizer))
        
        self.sep_id = self.tokenizer.sep_token_id
        self.eos_id = self.tokenizer.eos_token_id

    def load_data(self, file_path):
        """加载并处理新闻数据"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = [json.loads(line) for line in f]
        
        processed = []
        for item in data:
            # 将title和content合并为输入，用<sep>分隔
            text = f"{item['title']} {self.tokenizer.sep_token} {item['content']}"
            # 自动生成回复（实际应用应使用真实对话数据）
            response = self._generate_response(item['content'])
            processed.append({
                "input": text,
                "target": response + " " + self.tokenizer.eos_token
            })
        return processed

    def _generate_response(self, text):
        """模拟生成回复（实际应用应使用真实对话对）"""
        if "阿根廷" in text:
            return "这是关于南美的新闻"
        elif "韩国" in text:
            return "这是涉及韩国的国际新闻"
        else:
            return "这是一则值得关注的新闻报道"

    def preprocess(self, examples):
        """预处理函数"""
        # 合并输入和目标
        full_text = [
            f"{inp} {self.tokenizer.sep_token} {tgt}"
            for inp, tgt in zip(examples["input"], examples["target"])
        ]
        return self.tokenizer(
            full_text,
            truncation=True,
            max_length=256,
            padding="max_length"
        )

    def train(self, data_path, output_dir="./news_sft"):
        # 加载数据
        raw_data = self.load_data(data_path)
        
        # 转换为Dataset
        dataset = Dataset.from_dict({
            "input": [x["input"] for x in raw_data],
            "target": [x["target"] for x in raw_data]
        })
        
        # 预处理
        tokenized_dataset = dataset.map(
            self.preprocess,
            batched=True,
            remove_columns=["input", "target"]
        )

        # 训练参数
        training_args = TrainingArguments(
            output_dir=output_dir,
            per_device_train_batch_size=8,
            num_train_epochs=3,
            logging_dir=f"{output_dir}/logs",
            logging_steps=100,
            save_steps=500,
            learning_rate=5e-5,
            prediction_loss_only=True,
            evaluation_strategy="no",
            save_total_limit=2
        )

        # 创建Trainer
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=tokenized_dataset,
            data_collator=self.data_collator,
        )

        # 开始训练
        trainer.train()
        
        # 保存模型
        trainer.save_model(f"{output_dir}/final_model")
        self.tokenizer.save_pretrained(f"{output_dir}/final_model")
        print(f"训练完成，模型已保存到 {output_dir}/final_model")

    def generate_response(self, input_text, max_length=50):
        """生成回复"""
        input_ids = self.tokenizer.encode(
            f"{input_text} {self.tokenizer.sep_token}",
            return_tensors="pt"
        )
        
        # 创建注意力mask
        attention_mask = torch.ones_like(input_ids)
        
        # 自回归生成
        for _ in range(max_length):
            outputs = self.model(
                input_ids=input_ids,
                attention_mask=attention_mask
            )
            
            next_token_logits = outputs.logits[:, -1, :]
            next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)
            
            # 如果生成eos则停止
            if next_token.item() == self.eos_id:
                break
                
            input_ids = torch.cat([input_ids, next_token], dim=-1)
            attention_mask = torch.cat([
                attention_mask, 
                torch.ones(1, 1, dtype=torch.long)
            ], dim=-1)
        
        # 解码时跳过输入部分
        generated_ids = input_ids[0, len(input_ids[0])//2:]
        return self.tokenizer.decode(generated_ids, skip_special_tokens=True)

if __name__ == "__main__":
    # 初始化训练器
    trainer = NewsSFTTrainer()
    
    # 训练模型（使用您的sample_data.json）
    trainer.train("sample_data.json")
    
    # 测试生成
    test_input = "国际通用航空大会沈阳飞行家表演队一飞机发生坠机，伤亡不明 <sep> 今天上午..."
    response = trainer.generate_response(test_input)
    print(f"输入: {test_input}\n生成回复: {response}")
