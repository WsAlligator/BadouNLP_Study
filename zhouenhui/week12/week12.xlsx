	位置编码	transformer结构	多头机制	ff层设计	归一化层选择	激活函数	是否使用bias
baichuan2-7b	RoPE	串行	传统方式	gated形式	RMSnorm/pre norm	SiLU	无bias
baichuan2-13b	Alibi	串行	传统方式	gated形式	RMSnorm/pre norm	SiLU	无bias
chatglm2	RoPE	串行	multi query	gated形式	RMSnorm/pre norm	SiLU	qkv有bias，其他线性层无bias
llama2	RoPE	串行	multi query	gated形式	RMSnorm/pre norm	SiLU	无bias
moss	RoPE	平行	传统方式	传统方式	LayerNorm	gelu_new	sa无bias, ff有bias
deepseek_v3	RoPE	串行	传统方式	gated形式	RMSnorm/pre norm	SiLU	无bias
resnet	无	无	无	无	BatchNorm	ReLU	有Bias
gpt2	Learned	串行	传统方式	标准FFN	LayerNorm/pre norm	GELU	有Bias
glm4-moe	RoPE	串行	传统方式	MoE结构 + gated FFN（每个专家内部）	RMSnorm/pre norm	SiLU	无Bias
llama4	RoPE	串行	传统方式	gated形式	RMSnorm/pre norm	SiLU	无bias
